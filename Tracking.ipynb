{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad04b49",
   "metadata": {},
   "source": [
    "## Preparando l'ambiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac362c00",
   "metadata": {},
   "source": [
    "#### Ultralytics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a467106c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics==8.3.19 --quiet\n",
    "\n",
    "from IPython.display import clear_output\n",
    "clear_output()\n",
    "\n",
    "!yolo settings sync=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89633d01",
   "metadata": {},
   "source": [
    "#### Supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf1da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"supervision[assets]>=1.0.0,<2.0.0\" --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed027035",
   "metadata": {},
   "source": [
    "#### Motmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d368e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install motmetrics --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38fd28a",
   "metadata": {},
   "source": [
    "#### import librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd87b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "import motmetrics as mm\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import display, Image\n",
    "\n",
    "import ultralytics\n",
    "ultralytics.checks()\n",
    "print(sv.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb095b0f",
   "metadata": {},
   "source": [
    "#### Verifica GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d2b8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"nvidia-smi\" non � riconosciuto come comando interno o esterno,\n",
      " un programma eseguibile o un file batch.\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b38f3d6",
   "metadata": {},
   "source": [
    "#### Connessione a drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a3edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5f6b1b",
   "metadata": {},
   "source": [
    "#### Definizione percorsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bc4977",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/content/drive/MyDrive/Tracking_project'\n",
    "data_yaml_path = os.path.join(base_dir, 'dataset', 'data.yaml')\n",
    "\n",
    "load_previous_model = True\n",
    "if load_previous_model:\n",
    "  results_dir = os.path.join(base_dir, 'runs', 'detect', 'first_train18')\n",
    "  print(f\"Caricamento del modello da {results_dir}\")\n",
    "else:\n",
    "  results_dir = None\n",
    "  print(\"Un nuovo training verrà eseguito\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a540279",
   "metadata": {},
   "source": [
    "## Semi-supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84560a42",
   "metadata": {},
   "source": [
    "#### Pseudo labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f37433",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {base_dir}\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "model_path = os.path.join(results_dir, 'weights', 'best.pt')\n",
    "source = os.path.join(base_dir, \"video_tagliato_finale.mp4\")\n",
    "\n",
    "pseudo_labels_dir = os.path.join(base_dir, \"dataset\", \"labels\", \"train_pseudo\")\n",
    "os.makedirs(pseudo_labels_dir, exist_ok=True)\n",
    "\n",
    "confidence_threshold = 0.3\n",
    "\n",
    "model = YOLO(model_path)\n",
    "video_info = sv.VideoInfo.from_video_path(source)\n",
    "frame_generator = sv.get_video_frames_generator(source_path=source)\n",
    "\n",
    "print(\"Inizio generazione pseudo-labels...\")\n",
    "\n",
    "for frame_index, frame in enumerate(tqdm(frame_generator, total=video_info.total_frames)):\n",
    "    results = model(frame, verbose=False)[0]\n",
    "\n",
    "    yolo_format_labels = []\n",
    "    for box in results.boxes:\n",
    "        if box.conf[0] >= confidence_threshold:\n",
    "            class_id = int(box.cls[0])\n",
    "            xywhn = box.xywhn[0]\n",
    "            x_center, y_center, width, height = xywhn\n",
    "\n",
    "            yolo_format_labels.append(f\"{class_id} {x_center} {y_center} {width} {height}\")\n",
    "\n",
    "    if yolo_format_labels:\n",
    "        label_path = os.path.join(pseudo_labels_dir, f\"frame_{frame_index:06d}.txt\")\n",
    "        with open(label_path, 'w') as f:\n",
    "            f.write(\"\\n\".join(yolo_format_labels))\n",
    "\n",
    "print(f\"Pseudo-labels salvate in: {pseudo_labels_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd87211",
   "metadata": {},
   "source": [
    "#### Rinomina file pseudo-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79610faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {base_dir}\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "pseudo_labels_path = os.path.join(base_dir, \"dataset\", \"labels\", \"pseudo\")\n",
    "START_INDEX = 270\n",
    "\n",
    "print(f\"Inizio la rinomina dei file in: {pseudo_labels_path}\")\n",
    "print(f\"Il nuovo indice di partenza sarà: {START_INDEX}\")\n",
    "\n",
    "# Ottieni e ordina i file .txt validi\n",
    "file_list = sorted(\n",
    "    [f for f in os.listdir(pseudo_labels_path) if re.match(r'^frame_\\d{6}\\.txt$', f)]\n",
    ")\n",
    "\n",
    "# Prima passata: rinomina temporaneamente per evitare conflitti\n",
    "for i, filename in enumerate(file_list):\n",
    "    old_path = os.path.join(pseudo_labels_path, filename)\n",
    "    temp_path = os.path.join(pseudo_labels_path, f\"temp_{i:06d}.txt\")\n",
    "    os.rename(old_path, temp_path)\n",
    "\n",
    "# Seconda passata: rinomina mantenendo distanza originale + offset\n",
    "temp_files = sorted(\n",
    "    [f for f in os.listdir(pseudo_labels_path) if f.startswith(\"temp_\")]\n",
    ")\n",
    "\n",
    "for temp_filename in temp_files:\n",
    "    # Estrai l'indice originale dal nome temporaneo associato al file\n",
    "    i = int(re.search(r'temp_(\\d+)\\.txt', temp_filename).group(1))\n",
    "    original_filename = file_list[i]\n",
    "\n",
    "    try:\n",
    "        original_index = int(re.search(r'_(\\d{6})\\.txt', original_filename).group(1))\n",
    "    except AttributeError:\n",
    "        print(f\"Errore nel leggere l'indice da '{original_filename}', salto.\")\n",
    "        continue\n",
    "\n",
    "    new_index = START_INDEX + original_index\n",
    "    new_filename = f\"frame_{new_index:06d}.txt\"\n",
    "\n",
    "    old_path = os.path.join(pseudo_labels_path, temp_filename)\n",
    "    new_path = os.path.join(pseudo_labels_path, new_filename)\n",
    "    os.rename(old_path, new_path)\n",
    "\n",
    "    print(f\"Rinominato: '{original_filename}' -> '{new_filename}'\")\n",
    "\n",
    "print(\"\\nRinomina completata!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592803da",
   "metadata": {},
   "source": [
    "#### Stampa di un frame con pseudo-labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cbae18",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {base_dir}\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import supervision as sv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "source = os.path.join(base_dir, \"video_tagliato_finale.mp4\")\n",
    "pseudo_labels_path = os.path.join(base_dir, \"dataset\", \"labels\", \"pseudo\")\n",
    "\n",
    "START_INDEX = 270\n",
    "FRAME_TO_INSPECT = 274\n",
    "\n",
    "cap = cv2.VideoCapture(source)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, FRAME_TO_INSPECT-START_INDEX)\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "h, w, _ = frame.shape\n",
    "\n",
    "label_file_name = f\"frame_{FRAME_TO_INSPECT:06d}.txt\"\n",
    "label_path = os.path.join(pseudo_labels_path, label_file_name)\n",
    "\n",
    "if os.path.exists(label_path) and os.path.getsize(label_path) > 0:\n",
    "    yolo_data = np.loadtxt(label_path, ndmin=2)\n",
    "\n",
    "    class_ids = yolo_data[:, 0].astype(int)\n",
    "    boxes_yolo = yolo_data[:, 1:5]\n",
    "\n",
    "    boxes_xyxy = np.zeros_like(boxes_yolo)\n",
    "    boxes_xyxy[:, 0] = (boxes_yolo[:, 0] - boxes_yolo[:, 2] / 2) * w\n",
    "    boxes_xyxy[:, 1] = (boxes_yolo[:, 1] - boxes_yolo[:, 3] / 2) * h\n",
    "    boxes_xyxy[:, 2] = (boxes_yolo[:, 0] + boxes_yolo[:, 2] / 2) * w\n",
    "    boxes_xyxy[:, 3] = (boxes_yolo[:, 1] + boxes_yolo[:, 3] / 2) * h\n",
    "\n",
    "    detections = sv.Detections(xyxy=boxes_xyxy, class_id=class_ids)\n",
    "\n",
    "    box_annotator = sv.BoxAnnotator(thickness=2)\n",
    "    label_annotator = sv.LabelAnnotator(text_scale=0.5)\n",
    "    labels = [model.model.names[class_id] for class_id in detections.class_id]\n",
    "    annotated_frame = box_annotator.annotate(scene=frame.copy(), detections=detections)\n",
    "    annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)\n",
    "\n",
    "    sv.plot_image(image=annotated_frame, size=(10, 10))\n",
    "else:\n",
    "    print(f\"Nessun file di etichetta trovato per il frame {FRAME_TO_INSPECT}.\")\n",
    "    sv.plot_image(image=frame, size=(10, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cd1f3f",
   "metadata": {},
   "source": [
    "## Yolov8 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4168bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {base_dir}\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "if not load_previous_model:\n",
    "\n",
    "    print(\"Esecuzione di un nuovo training in corso...\")\n",
    "\n",
    "    model = YOLO('yolov8m.pt')\n",
    "    results = model.train(\n",
    "    task='detect',\n",
    "    data=data_yaml_path,\n",
    "    epochs=100,\n",
    "    imgsz=960,\n",
    "    plots=True,\n",
    "    patience=10,\n",
    "    name='first_train'\n",
    "    )\n",
    "\n",
    "    results_dir = results.save_dir\n",
    "    print(f\"I risultati sono stati salvati in: {results_dir}\")\n",
    "else:\n",
    "    results_dir = os.path.join(base_dir, 'runs', 'detect', 'first_train18')\n",
    "    print(f\"Caricamento del modello da {results_dir}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83699e08",
   "metadata": {},
   "source": [
    "#### Matrice di confusione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e084d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=f'{results_dir}/confusion_matrix.png', width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8f0f9a",
   "metadata": {},
   "source": [
    "#### Grafici metriche d'apprendimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545e1933",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=f'{results_dir}/results.png', width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c991f5",
   "metadata": {},
   "source": [
    "#### Batch di rilevazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e2c658",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=f'{results_dir}/val_batch0_pred.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b6ee8e",
   "metadata": {},
   "source": [
    "#### Detection test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42395bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {base_dir}\n",
    "\n",
    "model_path = os.path.join(results_dir, 'weights', 'best.pt')\n",
    "\n",
    "source_test_image = os.path.join(base_dir, 'dataset', 'images', 'test')\n",
    "\n",
    "model = YOLO(model_path)\n",
    "\n",
    "prediction_results = model.predict(source=source_test_image, conf=0.25, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abd3231",
   "metadata": {},
   "source": [
    "### Stampa rilevazioni su frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b30bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=f'{base_dir}/result_image_detection.png', width=600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fd25b2",
   "metadata": {},
   "source": [
    "## Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd {base_dir}\n",
    "\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "import supervision as sv\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "model_path = os.path.join(results_dir, 'weights', 'best.pt')\n",
    "INPUT_VIDEO_PATH = os.path.join(base_dir, \"output120.mp4\")\n",
    "OUTPUT_VIDEO_PATH = os.path.join(base_dir, \"risultato_tracking120_3.mp4\")\n",
    "results_tracking_path = os.path.join(base_dir, \"tracking_12.txt\")\n",
    "\n",
    "model = YOLO(model_path)\n",
    "video_info = sv.VideoInfo.from_video_path(INPUT_VIDEO_PATH)\n",
    "\n",
    "byte_tracker = sv.ByteTrack(\n",
    "    track_activation_threshold=0.25,\n",
    "    lost_track_buffer=video_info.fps * 2,\n",
    "    frame_rate=video_info.fps\n",
    ")\n",
    "\n",
    "box_annotator = sv.BoxAnnotator(thickness=2)\n",
    "trace_annotator = sv.TraceAnnotator(thickness=2, trace_length=video_info.fps)\n",
    "\n",
    "label_annotator = sv.LabelAnnotator(\n",
    "    text_position=sv.Position.TOP_CENTER,\n",
    "    text_scale=0.5,\n",
    "    text_color=sv.Color.WHITE,\n",
    "    text_thickness=1)\n",
    "\n",
    "mot_results = []\n",
    "\n",
    "def process_frame(frame: np.ndarray, index: int) -> np.ndarray:\n",
    "\n",
    "    results = model(frame, imgsz=960, verbose=False)[0]\n",
    "    detections = sv.Detections.from_ultralytics(results)\n",
    "\n",
    "    detections = byte_tracker.update_with_detections(detections)\n",
    "\n",
    "    annotated_frame = frame.copy()\n",
    "    labels = []\n",
    "\n",
    "    for box, confidence, class_id, tracker_id, in zip(\n",
    "        detections.xyxy,\n",
    "        detections.confidence,\n",
    "        detections.class_id,\n",
    "        detections.tracker_id\n",
    "    ):\n",
    "      if tracker_id is not None:\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        width = x_max - x_min\n",
    "        height = y_max - y_min\n",
    "        mot_results.append(f\"{index + 1}, {tracker_id}, {x_min}, {y_min}, {width}, {height}, {confidence}, -1, -1, -1\\n\")\n",
    "\n",
    "        labels.append(f\"ID: {tracker_id}\")\n",
    "\n",
    "    annotated_frame = trace_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "    annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
    "    annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)\n",
    "\n",
    "    return annotated_frame\n",
    "\n",
    "sv.process_video(\n",
    "    source_path=INPUT_VIDEO_PATH,\n",
    "    target_path=OUTPUT_VIDEO_PATH,\n",
    "    callback=process_frame\n",
    ")\n",
    "\n",
    "with open(results_tracking_path, 'w') as f:\n",
    "    f.writelines(mot_results)\n",
    "\n",
    "print(f\"Il video risultato è stato salvato in: {OUTPUT_VIDEO_PATH}\")\n",
    "print(f\"I risultati per la valutazione sono stati salvati in: {results_tracking_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816d9f11",
   "metadata": {},
   "source": [
    "#### Valutazione Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559e4765",
   "metadata": {},
   "outputs": [],
   "source": [
    "import motmetrics as mm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "truth_path = os.path.join(base_dir, \"dataset\", \"test_set.txt\")\n",
    "tracking_path = os.path.join(base_dir, \"risultato_tracking.txt\")\n",
    "\n",
    "truth_loader = mm.io.loadtxt(truth_path, fmt=\"mot15-2D\")\n",
    "tracking_loader = mm.io.loadtxt(tracking_path, fmt=\"mot15-2D\")\n",
    "\n",
    "acc = mm.MOTAccumulator(auto_id=True)\n",
    "\n",
    "for frame_id in truth_loader.index.get_level_values('FrameId').unique():\n",
    "  if frame_id not in tracking_loader.index.get_level_values('FrameId'):\n",
    "        continue\n",
    "\n",
    "  truth_frame = truth_loader.loc[frame_id]\n",
    "  tracking_frame = tracking_loader.loc[frame_id]\n",
    "\n",
    "  dist = mm.distances.iou_matrix(truth_frame[['X', 'Y', 'Width', 'Height']].values, tracking_frame[['X', 'Y', 'Width', 'Height']].values, max_iou=0.5)\n",
    "  acc.update(truth_frame.index.get_level_values('Id').tolist(), tracking_frame.index.get_level_values('Id').tolist(), dist, frameid = frame_id)\n",
    "\n",
    "m_handler = mm.metrics.create()\n",
    "\n",
    "met = m_handler.compute(acc, metrics = mm.metrics.motchallenge_metrics, name='acc')\n",
    "print(met)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
